{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYl0mIF7XHMW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Uf6yfDBXXUpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rar_path = '/content/drive/My Drive/TrashNet/TrashNet.rar'\n",
        "extract_path = '/content/dataset'\n",
        "\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "!unrar x -o+ \"{rar_path}\" \"{extract_path}\""
      ],
      "metadata": {
        "id": "eEyff3LaXW13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = 'dataset/TrashNet'\n",
        "classes = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(validation_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "H_OuT_OTXmV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_valid_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            img.verify()\n",
        "        return True\n",
        "    except (IOError, SyntaxError) as e:\n",
        "        return False"
      ],
      "metadata": {
        "id": "Y6GzE8wNXptK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            if img.mode in (\"P\", \"RGBA\"):\n",
        "                img = img.convert(\"RGBA\")\n",
        "            else:\n",
        "                img = img.convert(\"RGB\")\n",
        "            img.save(file_path)\n",
        "    except (IOError, SyntaxError) as e:\n",
        "        os.remove(file_path)"
      ],
      "metadata": {
        "id": "uQ4fLZy1XqCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for cls in classes:\n",
        "    class_dir = os.path.join(base_dir, cls)\n",
        "    for filename in os.listdir(class_dir):\n",
        "        file_path = os.path.join(class_dir, filename)\n",
        "        if filename.lower().endswith(('.jpg', '.JPG')):\n",
        "            if is_valid_image(file_path):\n",
        "                convert_image(file_path)\n",
        "            else:\n",
        "                os.remove(file_path)\n",
        "        else:\n",
        "            os.remove(file_path)"
      ],
      "metadata": {
        "id": "3M2NK-e7XtmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_ratio = 0.8\n",
        "\n",
        "for cls in classes:\n",
        "    class_dir = os.path.join(base_dir, cls)\n",
        "    images = os.listdir(class_dir)\n",
        "    random.shuffle(images)\n",
        "\n",
        "    split_point = int(split_ratio * len(images))\n",
        "    train_images = images[:split_point]\n",
        "    validation_images = images[split_point:]\n",
        "\n",
        "    for img in train_images:\n",
        "        source = os.path.join(class_dir, img)\n",
        "        destination = os.path.join(train_dir, cls, img)\n",
        "        os.makedirs(os.path.join(train_dir, cls), exist_ok=True)\n",
        "        shutil.move(source, destination)\n",
        "\n",
        "    for img in validation_images:\n",
        "        source = os.path.join(class_dir, img)\n",
        "        destination = os.path.join(validation_dir, cls, img)\n",
        "        os.makedirs(os.path.join(validation_dir, cls), exist_ok=True)\n",
        "        if img not in train_images:  # Sprawdź, czy obraz nie został już użyty w zbiorze treningowym\n",
        "            shutil.move(source, destination)"
      ],
      "metadata": {
        "id": "7EuCz842XvPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/dataset/TrashNet'\n",
        "for cls in classes:\n",
        "    folder_path = os.path.join(base_path, cls)\n",
        "    if os.path.exists(folder_path):\n",
        "        shutil.rmtree(folder_path)"
      ],
      "metadata": {
        "id": "5UycyJDTXxOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "num_classes = len(train_generator.class_indices)"
      ],
      "metadata": {
        "id": "-mWgFf9-XyY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define TensorBoard callback\n",
        "def get_tensorboard_callback(model_name):\n",
        "    log_dir = f\"logs/{model_name}_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "    return tensorboard_callback"
      ],
      "metadata": {
        "id": "CZbYk8Q7YG1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN MODEL\n"
      ],
      "metadata": {
        "id": "6yGv9nCdYKEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple CNN Model\n",
        "def simple_cnn_model(input_shape=(224, 224, 3), classes=num_classes):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(classes, activation='softmax')\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "USpHh7htYF2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn = simple_cnn_model()\n",
        "model_cnn.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_cnn.summary()"
      ],
      "metadata": {
        "id": "KjEzpHkGYNhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "    ModelCheckpoint('simple_cnn_best_model.h5', monitor='val_loss', save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001),\n",
        "    get_tensorboard_callback('simple_cnn')\n",
        "]"
      ],
      "metadata": {
        "id": "aTvk0rsVYOeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_cnn = model_cnn.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    epochs=25,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    callbacks=callbacks,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "model_cnn.save('simple_cnn_final_model.h5')  # Save final model"
      ],
      "metadata": {
        "id": "6ngdjCaGYP0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG MODEL"
      ],
      "metadata": {
        "id": "upOlawHgYQ_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG Model\n",
        "def VGG19(input_shape=(224, 224, 3), classes=num_classes):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    # Block 2\n",
        "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    # Block 3\n",
        "    model.add(tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    # Block 4\n",
        "    model.add(tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    # Block 5\n",
        "    model.add(tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    # Flattening\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "    # Fully connected layers\n",
        "    model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "gvqv1bFoYTun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_vgg = VGG19()\n",
        "model_vgg.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_vgg.summary()"
      ],
      "metadata": {
        "id": "mg9ZN8GLYWTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "    ModelCheckpoint('vgg19_best_model.h5', monitor='val_loss', save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001),\n",
        "    get_tensorboard_callback('vgg19')\n",
        "]"
      ],
      "metadata": {
        "id": "teatIeTTYX9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_vgg = model_vgg.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    epochs=25,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    callbacks=callbacks,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "model_vgg.save('vgg19_final_model.h5')  # Save final model"
      ],
      "metadata": {
        "id": "k1bTgPxHYYu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CUSTOM RESNET50 MODEL"
      ],
      "metadata": {
        "id": "7DPYw4ecYbLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom ResNet Model\n",
        "def identity_block(X, f, filters):\n",
        "    F1, F2, F3 = filters\n",
        "    X_shortcut = X\n",
        "\n",
        "    X = Conv2D(F1, (1, 1), padding='valid')(X)\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(F2, (f, f), padding='same')(X)\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(F3, (1, 1), padding='valid')(X)\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "13nRUnFbYd2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convolutional_block(X, f, filters, s=2):\n",
        "    F1, F2, F3 = filters\n",
        "    X_shortcut = X\n",
        "\n",
        "    X = Conv2D(F1, (1, 1), strides=(s, s), padding='valid')(X)\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(F2, (f, f), padding='same')(X)\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(F3, (1, 1), padding='valid')(X)\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "\n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides=(s, s), padding='valid')(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis=3)(X_shortcut)\n",
        "\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "dYQBOQ1CYgYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet50(input_shape=(224, 224, 3), classes=num_classes):\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    X = tf.keras.layers.ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2), padding='valid')(X)\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[64, 64, 256], s=1)\n",
        "    X = identity_block(X, 3, [64, 64, 256])\n",
        "    X = identity_block(X, 3, [64, 64, 256])\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[128, 128, 512], s=2)\n",
        "    X = identity_block(X, 3, [128, 128, 512])\n",
        "    X = identity_block(X, 3, [128, 128, 512])\n",
        "    X = identity_block(X, 3, [128, 128, 512])\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], s=2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[512, 512, 2048], s=2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048])\n",
        "    X = identity_block(X, 3, [512, 512, 2048])\n",
        "\n",
        "    X = GlobalAveragePooling2D()(X)\n",
        "\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(1024, activation='relu')(X)\n",
        "    X = Dropout(0.5)(X)\n",
        "    X = Dense(classes, activation='softmax')(X)\n",
        "\n",
        "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "wCsWmwLUYi8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet_custom = ResNet50()\n",
        "model_resnet_custom.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_resnet_custom.summary()"
      ],
      "metadata": {
        "id": "8ZsAA-qBYkcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "    ModelCheckpoint('resnet50_custom_best_model.h5', monitor='val_loss', save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001),\n",
        "    get_tensorboard_callback('resnet50_custom')\n",
        "]"
      ],
      "metadata": {
        "id": "zqf3VEzoYlXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_resnet_custom = model_resnet_custom.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    epochs=25,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    callbacks=callbacks,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "model_resnet_custom.save('resnet50_custom_final_model.h5')  # Save final model"
      ],
      "metadata": {
        "id": "glYEgRZPYmkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BUILT-IN RESNET 50 MODEL"
      ],
      "metadata": {
        "id": "rFwAHJL-Yp45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Built-in ResNet50 Model\n",
        "model_resnet50 = tf.keras.applications.ResNet50(\n",
        "    include_top=True,\n",
        "    weights=None,\n",
        "    input_tensor=None,\n",
        "    input_shape=(224, 224, 3),\n",
        "    pooling=None,\n",
        "    classes=num_classes,\n",
        "    classifier_activation='softmax'\n",
        ")"
      ],
      "metadata": {
        "id": "hu2BrnOxYsZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet50.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_resnet50.summary()\n"
      ],
      "metadata": {
        "id": "TGeIhyh8Yuxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "    ModelCheckpoint('resnet50_builtin_best_model.h5', monitor='val_loss', save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001),\n",
        "    get_tensorboard_callback('resnet50_builtin')\n",
        "]"
      ],
      "metadata": {
        "id": "9twSe5BYYvqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_resnet50 = model_resnet50.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    epochs=25,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    callbacks=callbacks,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "model_resnet50.save('resnet50_builtin_final_model.h5')  # Save final model"
      ],
      "metadata": {
        "id": "7U-w25OXYw-b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}